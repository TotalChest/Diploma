1. Тема.
Использование обучения с подкреплением  в задаче автоматического тестирования мобильных приложений

2. Актуальность.
Сегодня смартфон занимает существенную чать жизни каждого человека. Исследования покаывают, что более 80% времени использования смартфона - работа с приложниями. Всвязи с этим рынок мобильной разработки интенсивно развивается. И ему необходимы эффективные и качественные решения в области контроля качества продукта.
Мы рассматриваем систему Android, так так это одна из самых популярных операционных систем с окрытым исходным кодом.
Под тестированием в данном контексте понимается динамический обход состояний мобильного приложения с целью покрытия как можно большего их числа. Автоматизация данного процесса необходима в связи с тем, что ручное динамическое тестирование это дорого и ненадежно.
Большие промышленные компании заинтерисованы в продуктах автоматического динамического тестирования своих приложений и в частности в институте разрабатывается такой продукт.

3. Существующие решения.
Существующие стратегии динамического тестирования можно разделить на четыре класса:
- Random-based - основаны на случайных нажатиях на экран (очень быстро, невоспроизводимые тесты, тесты отличные от реального взаимодействия с устройством)
- Search-based (На практике хуже чем, model-based) - основаны на приближенном решении задач оптимизации (генетические алгоритм)
- Model-based - основаны на построении модели приложения либо до тестирования, либо во время тестирования (state-of-the-art подходы, все сравнисаются с ними)
- Hybrid - совмещвет в себе две стратегии (random + model-based)

4. Обучение с подкрепление
Есть несколько работ по внедрению Q-learning алгоритмов для динамического тестирования, но они обладают некоторыми недостатками:
- Нет открытого исходного кода с реализацией
- Используют медленный UI-automator (в отличии от быстрого DroidBot)
- Сомнительный дизайн элементов RL (представление состояние)
Также некоторые, близкие к нашей задаче, работы используют Q-learning подход для десктоп приложений. Поэтому основной задачей ставится внедрение RL в систему DroidBot

5. Связка Humanoid  и DroidBot интнресна тем, что она является state-of-the-art решением и есть доступ к ее реализации.
Основными компонентами для тетирования в этой системе являются:
- Тестируемое приложение
- Устройство на котором проводятся тесты или эмулятор
- Инструмент взаиможействия с приложением (DroidBot)
- Глубокая нейронная сеть для предстказания действий по тестированию.
Также Humanoid интересен тем, что его действия обучаются быть максимально похожими на действия пользователя.

6. Общая схема функционарования системы Humanoid + DroidBot показана на рисунке.
- Приложение возвращает текущее сосотоние
- Обрабатываем состоние и подаем на вход нейросети вместе с историей предыдущих состояний и списком возможных действий.
- На выходе получаем наиболее релевантное действие в текущем состоянии
- Воспроизводим действие в приложении

7. Наша основная задача будет состоять в том, чтобы в этой схеме изменить модель предсказания на модель обучения с подкреплением.

8. Постановка задачи.

9. Текущие результаты.
Изучил архитектуру Humanoid. Изучил цикл обработки и движения данных в Humanoid. Изучил основные метрики качества динамического тестирования. Прочитал статьи про реализацию Q-learning подходов в динамическом тестировании.

10. Планы.
Реализовать baseline версию подхода с использованием Q-Learning. Пытаться ее улучшить используя разные функции вознаграждения (в том числе вознаграждение за человекоподобность) или разное представление состояний в модели. Также искать альтернативные методы обучения с подкреплением (помимо Q-learning)
